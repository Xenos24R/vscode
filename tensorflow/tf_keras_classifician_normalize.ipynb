{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python38164bit909497d13ec443c9ad1939dfb1e78050",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_all,y_train_all),(x_test,y_test) = fashion_mnist.load_data()\n",
    "x_valid,x_train = x_train_all[:5000],x_train_all[5000:]\n",
    "y_valid,y_train = y_train_all[:5000],y_train_all[5000:]\n",
    "\n",
    "print(x_valid.shape,y_valid.shape)\n",
    "print(x_train.shape,y_valid.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = (x - u)/std\n",
    "#u是均值，std是方差\n",
    "#得到的结果符合均值是0，方差是1的正态分布\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sacler = StandardScaler()\n",
    "#x_train:[None,28,28] ->[None,784]\n",
    "#fit_transform要求数据是二维矩阵\n",
    "x_train_scaled = sacler.fit_transform(x_train.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)\n",
    "#归一化是所有的归一化的均值方差都要有训练集的均值方差\n",
    "x_valid_scaled = sacler.transform(x_valid.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)\n",
    "x_test_scaled = sacler.transform(x_test.astype(np.float32).reshape(-1,1)).reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(x_train_scaled),np.min(x_train_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.Sequential()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28,28]))#将数据展平\n",
    "model.add(keras.layers.Dense(300,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\"\"\"\n",
    "另一种表示模型的方法\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(300,activation=\"relu\"),\n",
    "    keras.layers.Dense(300,activation=\"relu\"),\n",
    "    keras.layers.Dense(10,activation=\"softmax\")\n",
    "])\n",
    "\"\"\"\n",
    "#relu: y=max(0,x)\n",
    "#softmax: 将向量变成概率分布   x=[x1,x2,x3]\n",
    "#    y = [e^x1/sum,e^x2/sum,e^x3/sum]   sum = e^x1 + e^x2 + e^x3\n",
    "\n",
    "\n",
    "#reason for sparse: y->index   y->one_hot->[]\n",
    "#即验证集y只是一个长度为样本数目的向量，对于每个样本来说只是一个index的值，计算损失函数时需要变为向量\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train,y_train,validation_data=(x_valid,y_valid),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "    plt.grid(True)\n",
    "    plt.gca().set_ylim(0,1)\n",
    "    plt.show()\n",
    "\n",
    "plot_learning_curves(history)"
   ]
  }
 ]
}